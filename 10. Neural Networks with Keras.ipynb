{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ef08cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eed342b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0864bbf4",
   "metadata": {},
   "source": [
    "### 10.2.2 시퀀셜 API를 사용하여 이미지 분류기 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f46b732",
   "metadata": {},
   "source": [
    "### 케라스를 사용하여 데이터셋 적재하기\n",
    "패션 MNIST 로드. 케라스는 keras.datasets에 널리 사용하는 데이터셋을 로드하기 위한 함수를 제공합니다. 이 데이터셋은 이미 훈련 세트와 테스트 세트로 나누어져 있습니다. 훈련 세트를 더 나누어 검증 세트를 만드는 것이 좋습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1a950aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876408f0",
   "metadata": {},
   "source": [
    "훈련 세트는 60,000개의 흑백 이미지입니다. 각 이미지의 크기는 28x28 픽셀입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99aa1d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8090829c",
   "metadata": {},
   "source": [
    "각 픽셀의 강도는 정수(0~255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66172730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12564f2",
   "metadata": {},
   "source": [
    "Validation set 확보하기\n",
    "\n",
    "Feature scaling: 255.0으로 나누어 0~1 사이 범위로 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faddf0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcad499b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[0], cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5917cecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 0, 7, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0301aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9aa3e9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7950e613",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "231c5a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x214c85a43a0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x214bda56ac0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x214bda56dc0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x214bdaba0a0>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aaf87b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2e328d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfec8748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(hidden1.name) is hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8a64371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0637226 ,  0.07438824, -0.05152804, ..., -0.0194061 ,\n",
       "         0.01138275, -0.04132742],\n",
       "       [-0.03396999, -0.06843049,  0.04856388, ..., -0.00677192,\n",
       "         0.0330404 ,  0.06899646],\n",
       "       [-0.04956627,  0.02234778,  0.04848079, ...,  0.03209908,\n",
       "         0.02644292, -0.02259306],\n",
       "       ...,\n",
       "       [-0.02052339, -0.04781845, -0.04229274, ..., -0.01550945,\n",
       "         0.05954559,  0.05509919],\n",
       "       [ 0.04665492, -0.03511155,  0.03142676, ..., -0.06401388,\n",
       "         0.04515196,  0.03866563],\n",
       "       [-0.00579104,  0.03125899, -0.0213394 , ..., -0.00264649,\n",
       "        -0.01526495, -0.02472506]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, biases = hidden1.get_weights()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64b6b50b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4652a5b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a09d1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6b7cfe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 2s 971us/step - loss: 0.7022 - accuracy: 0.7726 - val_loss: 0.5166 - val_accuracy: 0.8260\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 2s 908us/step - loss: 0.4834 - accuracy: 0.8321 - val_loss: 0.4618 - val_accuracy: 0.8340\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 2s 899us/step - loss: 0.4386 - accuracy: 0.8469 - val_loss: 0.4183 - val_accuracy: 0.8562\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 2s 903us/step - loss: 0.4123 - accuracy: 0.8537 - val_loss: 0.4250 - val_accuracy: 0.8476\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 2s 899us/step - loss: 0.3928 - accuracy: 0.8616 - val_loss: 0.4140 - val_accuracy: 0.8464\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 2s 901us/step - loss: 0.3766 - accuracy: 0.8661 - val_loss: 0.3670 - val_accuracy: 0.8744\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 2s 890us/step - loss: 0.3637 - accuracy: 0.8690 - val_loss: 0.3850 - val_accuracy: 0.8634\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 2s 897us/step - loss: 0.3525 - accuracy: 0.8743 - val_loss: 0.3639 - val_accuracy: 0.8766\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 2s 911us/step - loss: 0.3421 - accuracy: 0.8779 - val_loss: 0.4009 - val_accuracy: 0.8622\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 2s 907us/step - loss: 0.3319 - accuracy: 0.8806 - val_loss: 0.3570 - val_accuracy: 0.8748\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 2s 937us/step - loss: 0.3253 - accuracy: 0.8827 - val_loss: 0.3432 - val_accuracy: 0.8792\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.3155 - accuracy: 0.8871 - val_loss: 0.3364 - val_accuracy: 0.8790\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 2s 965us/step - loss: 0.3097 - accuracy: 0.8885 - val_loss: 0.3389 - val_accuracy: 0.8768\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 2s 913us/step - loss: 0.3029 - accuracy: 0.8902 - val_loss: 0.3340 - val_accuracy: 0.8840\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 2s 908us/step - loss: 0.2964 - accuracy: 0.8935 - val_loss: 0.3320 - val_accuracy: 0.8876\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 2s 894us/step - loss: 0.2901 - accuracy: 0.8948 - val_loss: 0.3318 - val_accuracy: 0.8858\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 2s 899us/step - loss: 0.2849 - accuracy: 0.8970 - val_loss: 0.3329 - val_accuracy: 0.8766\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 2s 910us/step - loss: 0.2789 - accuracy: 0.8988 - val_loss: 0.3196 - val_accuracy: 0.8848\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 2s 922us/step - loss: 0.2745 - accuracy: 0.9001 - val_loss: 0.3126 - val_accuracy: 0.8886\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 2s 902us/step - loss: 0.2693 - accuracy: 0.9021 - val_loss: 0.3097 - val_accuracy: 0.8886\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 2s 906us/step - loss: 0.2634 - accuracy: 0.9045 - val_loss: 0.3433 - val_accuracy: 0.8740\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 2s 904us/step - loss: 0.2592 - accuracy: 0.9059 - val_loss: 0.3106 - val_accuracy: 0.8886\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 2s 920us/step - loss: 0.2548 - accuracy: 0.9072 - val_loss: 0.3015 - val_accuracy: 0.8956\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 2s 905us/step - loss: 0.2500 - accuracy: 0.9094 - val_loss: 0.3030 - val_accuracy: 0.8934\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 2s 895us/step - loss: 0.2466 - accuracy: 0.9105 - val_loss: 0.3061 - val_accuracy: 0.8876\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 2s 897us/step - loss: 0.2423 - accuracy: 0.9121 - val_loss: 0.3150 - val_accuracy: 0.8858\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 2s 909us/step - loss: 0.2371 - accuracy: 0.9142 - val_loss: 0.3112 - val_accuracy: 0.8876\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 2s 886us/step - loss: 0.2346 - accuracy: 0.9143 - val_loss: 0.2986 - val_accuracy: 0.8972\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 2s 894us/step - loss: 0.2296 - accuracy: 0.9167 - val_loss: 0.3018 - val_accuracy: 0.8906\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 2s 896us/step - loss: 0.2264 - accuracy: 0.9181 - val_loss: 0.2994 - val_accuracy: 0.8928\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d068e6",
   "metadata": {},
   "source": [
    "fit() 메서드를 호출할때 batch_size의 기본값은 32이다: 32 x 1719 = 55000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d94fa07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 1, 'epochs': 30, 'steps': 1719}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eae0ce18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n"
     ]
    }
   ],
   "source": [
    "print(history.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ebf2b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a759fd4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "559bf7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 551us/step - loss: 0.3301 - accuracy: 0.8839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3301498293876648, 0.883899986743927]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be09b0ae",
   "metadata": {},
   "source": [
    "모델을 사용해 예측을 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d18b2a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.99],\n",
       "       [0.  , 0.  , 0.99, 0.  , 0.01, 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785b07de",
   "metadata": {},
   "source": [
    "경고: model.predict_classes(X_new)는 삭제될 예정입니다. 대신 np.argmax(model.predict(X_new), axis=-1)를 사용하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a29af03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "#y_pred = model.predict_classes(X_new)\n",
    "y_pred = np.argmax(model.predict(X_new), axis=-1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98333d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a6587d",
   "metadata": {},
   "source": [
    "### 10.2.3 시퀀셜 API를 사용하여 회귀용 다층 퍼셉트론 만들기\n",
    "\n",
    "캘리포니아 주택 가격 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70c2428b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2373793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anpdi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 663us/step - loss: 1.6919 - val_loss: 0.8533\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 489us/step - loss: 0.7906 - val_loss: 0.7342\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 497us/step - loss: 0.7181 - val_loss: 0.6758\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 492us/step - loss: 0.6705 - val_loss: 0.6580\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 486us/step - loss: 0.6316 - val_loss: 0.5983\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 486us/step - loss: 0.5996 - val_loss: 0.5607\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 486us/step - loss: 0.5714 - val_loss: 0.5369\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 486us/step - loss: 0.5476 - val_loss: 0.5540\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 484us/step - loss: 0.5273 - val_loss: 0.4984\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 495us/step - loss: 0.5098 - val_loss: 0.4842\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 478us/step - loss: 0.4954 - val_loss: 0.4695\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 472us/step - loss: 0.4828 - val_loss: 0.4544\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 478us/step - loss: 0.4720 - val_loss: 0.4459\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 495us/step - loss: 0.4632 - val_loss: 0.4527\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 486us/step - loss: 0.4553 - val_loss: 0.4388\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 478us/step - loss: 0.4484 - val_loss: 0.4299\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 486us/step - loss: 0.4426 - val_loss: 0.4206\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 489us/step - loss: 0.4375 - val_loss: 0.4320\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 479us/step - loss: 0.4330 - val_loss: 0.4116\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 494us/step - loss: 0.4287 - val_loss: 0.4092\n",
      "162/162 [==============================] - 0s 329us/step - loss: 0.4173\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85939390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.417346328496933"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8565b655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6213154],\n",
       "       [1.5650287],\n",
       "       [3.2455006]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c89d804",
   "metadata": {},
   "source": [
    "### 10.2.4 함수형 API를 사용해 복잡한 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1da562bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e226c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 30)           270         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 30)           930         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 38)           0           input_1[0][0]                    \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            39          concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "322a63b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\\nhistory = model.fit(X_train, y_train, epochs=20,\\n                    validation_data=(X_valid, y_valid))\\nmse_test = model.evaluate(X_test, y_test)\\ny_pred = model.predict(X_new)\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "y_pred = model.predict(X_new)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ff2243",
   "metadata": {},
   "source": [
    "여러개의 입력 다루기: (특성 0에서 4까지) 5개의 특성을 와이드 경로에 보내고 (특성 2에서 7까지) 6개의 특성을 딥 경로에 전달하겠습니다. 3개의 특성(특성 2, 3, 4)은 양쪽에 모두 전달됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85997135",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(concat)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "57b604fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 0s 746us/step - loss: 1.9058 - val_loss: 2.9174\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 550us/step - loss: 0.7561 - val_loss: 1.3250\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 553us/step - loss: 0.6492 - val_loss: 0.7456\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 550us/step - loss: 0.6017 - val_loss: 0.5862\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 555us/step - loss: 0.5691 - val_loss: 0.5290\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 544us/step - loss: 0.5430 - val_loss: 0.5035\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 553us/step - loss: 0.5206 - val_loss: 0.4877\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 553us/step - loss: 0.5012 - val_loss: 0.4701\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 558us/step - loss: 0.4842 - val_loss: 0.4544\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 553us/step - loss: 0.4709 - val_loss: 0.4415\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 553us/step - loss: 0.4599 - val_loss: 0.4285\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 569us/step - loss: 0.4510 - val_loss: 0.4173\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 597us/step - loss: 0.4447 - val_loss: 0.4093\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 575us/step - loss: 0.4396 - val_loss: 0.4035\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 564us/step - loss: 0.4351 - val_loss: 0.3996\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 553us/step - loss: 0.4316 - val_loss: 0.3960\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 564us/step - loss: 0.4285 - val_loss: 0.3956\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 555us/step - loss: 0.4259 - val_loss: 0.3944\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 569us/step - loss: 0.4237 - val_loss: 0.3965\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 561us/step - loss: 0.4215 - val_loss: 0.3902\n",
      "162/162 [==============================] - 0s 360us/step - loss: 0.4155\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1733ece3",
   "metadata": {},
   "source": [
    "규제를 위한 보조 출력 추가하기:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "116617ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.concatenate([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux_output = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.models.Model(inputs=[input_A, input_B],\n",
    "                           outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f434af17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b2073b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 967us/step - loss: 2.2753 - main_output_loss: 2.0300 - aux_output_loss: 4.4827 - val_loss: 3.2896 - val_main_output_loss: 3.2651 - val_aux_output_loss: 3.5103\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 633us/step - loss: 0.9778 - main_output_loss: 0.7516 - aux_output_loss: 3.0140 - val_loss: 0.8392 - val_main_output_loss: 0.6591 - val_aux_output_loss: 2.4593\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 644us/step - loss: 0.7743 - main_output_loss: 0.6124 - aux_output_loss: 2.2316 - val_loss: 0.7136 - val_main_output_loss: 0.5579 - val_aux_output_loss: 2.1146\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 633us/step - loss: 0.6887 - main_output_loss: 0.5618 - aux_output_loss: 1.8310 - val_loss: 0.6862 - val_main_output_loss: 0.5484 - val_aux_output_loss: 1.9263\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 641us/step - loss: 0.6406 - main_output_loss: 0.5332 - aux_output_loss: 1.6066 - val_loss: 0.6297 - val_main_output_loss: 0.4937 - val_aux_output_loss: 1.8539\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 638us/step - loss: 0.6080 - main_output_loss: 0.5122 - aux_output_loss: 1.4705 - val_loss: 0.5969 - val_main_output_loss: 0.4686 - val_aux_output_loss: 1.7516\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 630us/step - loss: 0.5835 - main_output_loss: 0.4952 - aux_output_loss: 1.3783 - val_loss: 0.5723 - val_main_output_loss: 0.4616 - val_aux_output_loss: 1.5687\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 671us/step - loss: 0.5643 - main_output_loss: 0.4818 - aux_output_loss: 1.3066 - val_loss: 0.5461 - val_main_output_loss: 0.4430 - val_aux_output_loss: 1.4732\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 710us/step - loss: 0.5498 - main_output_loss: 0.4714 - aux_output_loss: 1.2549 - val_loss: 0.5258 - val_main_output_loss: 0.4343 - val_aux_output_loss: 1.3492\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 691us/step - loss: 0.5371 - main_output_loss: 0.4624 - aux_output_loss: 1.2099 - val_loss: 0.5092 - val_main_output_loss: 0.4255 - val_aux_output_loss: 1.2624\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 680us/step - loss: 0.5276 - main_output_loss: 0.4558 - aux_output_loss: 1.1732 - val_loss: 0.5011 - val_main_output_loss: 0.4236 - val_aux_output_loss: 1.1985\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 694us/step - loss: 0.5197 - main_output_loss: 0.4507 - aux_output_loss: 1.1402 - val_loss: 0.4883 - val_main_output_loss: 0.4164 - val_aux_output_loss: 1.1358\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 677us/step - loss: 0.5123 - main_output_loss: 0.4457 - aux_output_loss: 1.1113 - val_loss: 0.4806 - val_main_output_loss: 0.4122 - val_aux_output_loss: 1.0960\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 702us/step - loss: 0.5062 - main_output_loss: 0.4419 - aux_output_loss: 1.0849 - val_loss: 0.4764 - val_main_output_loss: 0.4109 - val_aux_output_loss: 1.0660\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 694us/step - loss: 0.5010 - main_output_loss: 0.4387 - aux_output_loss: 1.0610 - val_loss: 0.4732 - val_main_output_loss: 0.4102 - val_aux_output_loss: 1.0405\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 685us/step - loss: 0.4958 - main_output_loss: 0.4357 - aux_output_loss: 1.0367 - val_loss: 0.4763 - val_main_output_loss: 0.4160 - val_aux_output_loss: 1.0189\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 685us/step - loss: 0.4910 - main_output_loss: 0.4328 - aux_output_loss: 1.0151 - val_loss: 0.4667 - val_main_output_loss: 0.4074 - val_aux_output_loss: 0.9998\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 682us/step - loss: 0.4869 - main_output_loss: 0.4306 - aux_output_loss: 0.9936 - val_loss: 0.4717 - val_main_output_loss: 0.4152 - val_aux_output_loss: 0.9799\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 688us/step - loss: 0.4830 - main_output_loss: 0.4285 - aux_output_loss: 0.9740 - val_loss: 0.4558 - val_main_output_loss: 0.3977 - val_aux_output_loss: 0.9787\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 633us/step - loss: 0.4792 - main_output_loss: 0.4264 - aux_output_loss: 0.9538 - val_loss: 0.4750 - val_main_output_loss: 0.4226 - val_aux_output_loss: 0.9460\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20,\n",
    "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "82ffb661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 416us/step - loss: 0.4688 - main_output_loss: 0.4186 - aux_output_loss: 0.9205\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate(\n",
    "    [X_test_A, X_test_B], [y_test, y_test])\n",
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85876ee8",
   "metadata": {},
   "source": [
    "### 10.2.5 서브클래싱 API로 동적 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c0f7c27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.models.Model):\n",
    "    def __init__(self, units=30, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output\n",
    "\n",
    "model = WideAndDeepModel(30, activation=\"relu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3e5e66",
   "metadata": {},
   "source": [
    "모델 구조가 call() 메서드 안에 숨겨져 있어서 모델을 저장하거나 복사할 수 없다. 높은 유연성이 필요하지 않는다면 시퀀셜 API나 함수형 API를 사용하는 것이 좋다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc65b9e",
   "metadata": {},
   "source": [
    "### 10.2.6 모델 저장과 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "550e30eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"my_keras_model.h5\")\n",
    "# model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f022b1fd",
   "metadata": {},
   "source": [
    "시퀀셜, 함수형 API에서는 이 방식을 쓸 수 있지만 모델 서브클래싱에서는 사용할 수 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae18d815",
   "metadata": {},
   "source": [
    "### 10.2.7 콜백 사용하기\n",
    "훈련 도중에 체크포인트 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7fa05cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dd0735bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 0s 691us/step - loss: 2.2683 - val_loss: 1.1967\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 511us/step - loss: 0.8536 - val_loss: 0.8427\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 511us/step - loss: 0.6170 - val_loss: 0.5557\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 519us/step - loss: 0.5645 - val_loss: 0.5222\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 511us/step - loss: 0.5366 - val_loss: 0.4925\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 511us/step - loss: 0.5140 - val_loss: 0.4695\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 522us/step - loss: 0.4952 - val_loss: 0.4526\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 566us/step - loss: 0.4790 - val_loss: 0.4388\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 519us/step - loss: 0.4659 - val_loss: 0.4284\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 561us/step - loss: 0.4545 - val_loss: 0.4214\n",
      "162/162 [==============================] - 0s 354us/step - loss: 0.4375\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=10,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb])\n",
    "model = keras.models.load_model(\"my_keras_model.h5\") # 최상의 모델로 롤백\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f9f1ce",
   "metadata": {},
   "source": [
    "아래는 EarlyStopping 콜백을 사용하는 것으로 일정 epoch 동안 검증 세트에 대한 점수가 향상되지 않으면 훈련을 멈춤\n",
    "체크포인트 저장 콜백 + 얼리스탑핑 콜백을 함께 사용할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5adac42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 0s 724us/step - loss: 0.4448 - val_loss: 0.4098\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 528us/step - loss: 0.4365 - val_loss: 0.4091\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 514us/step - loss: 0.4295 - val_loss: 0.4052\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 522us/step - loss: 0.4232 - val_loss: 0.4037\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 500us/step - loss: 0.4179 - val_loss: 0.4000\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 517us/step - loss: 0.4131 - val_loss: 0.4162\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 517us/step - loss: 0.4093 - val_loss: 0.3930\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.4055 - val_loss: 0.4045\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 517us/step - loss: 0.4019 - val_loss: 0.4128\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 517us/step - loss: 0.3990 - val_loss: 0.3977\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 517us/step - loss: 0.3959 - val_loss: 0.3952\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 514us/step - loss: 0.3935 - val_loss: 0.3914\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 511us/step - loss: 0.3912 - val_loss: 0.3977\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 511us/step - loss: 0.3891 - val_loss: 0.3891\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 517us/step - loss: 0.3869 - val_loss: 0.3882\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 517us/step - loss: 0.3850 - val_loss: 0.3867\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 514us/step - loss: 0.3831 - val_loss: 0.3729\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 511us/step - loss: 0.3813 - val_loss: 0.3974\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 511us/step - loss: 0.3798 - val_loss: 0.3663\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.3781 - val_loss: 0.3935\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 514us/step - loss: 0.3768 - val_loss: 0.3986\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 517us/step - loss: 0.3754 - val_loss: 0.3830\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 519us/step - loss: 0.3742 - val_loss: 0.3856\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 514us/step - loss: 0.3727 - val_loss: 0.3767\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 514us/step - loss: 0.3714 - val_loss: 0.3630\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 517us/step - loss: 0.3702 - val_loss: 0.3589\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 517us/step - loss: 0.3692 - val_loss: 0.3755\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 517us/step - loss: 0.3680 - val_loss: 0.3589\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 503us/step - loss: 0.3668 - val_loss: 0.3739\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 517us/step - loss: 0.3657 - val_loss: 0.3828\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 519us/step - loss: 0.3647 - val_loss: 0.3591\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 511us/step - loss: 0.3637 - val_loss: 0.3707\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 514us/step - loss: 0.3629 - val_loss: 0.3626\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.3619 - val_loss: 0.3693\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.3609 - val_loss: 0.3803\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 511us/step - loss: 0.3599 - val_loss: 0.3800\n",
      "162/162 [==============================] - 0s 335us/step - loss: 0.3640\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                  restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb])\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f85d389",
   "metadata": {},
   "source": [
    "사용자 정의 콜백: 검증 손실과 훈련 손실의 비율 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd03eb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4efa7695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 0s 564us/step - loss: 0.3689 - val_loss: 0.3813\n",
      "\n",
      "val/train: 1.03\n"
     ]
    }
   ],
   "source": [
    "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
    "history = model.fit(X_train, y_train, epochs=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[val_train_ratio_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1d992d",
   "metadata": {},
   "source": [
    "### 10.2.8 텐서보드를 사용해 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "182cfd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b06ec61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2021_06_09-00_47_58'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2b28b9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e5c65956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 999us/step - loss: 2.3910 - val_loss: 11.9380\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 539us/step - loss: 0.9200 - val_loss: 0.7477\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 522us/step - loss: 0.6512 - val_loss: 0.5836\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 519us/step - loss: 0.5886 - val_loss: 0.5737\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 524us/step - loss: 0.5483 - val_loss: 0.5318\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 514us/step - loss: 0.5158 - val_loss: 0.4860\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 516us/step - loss: 0.4908 - val_loss: 0.4507\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 519us/step - loss: 0.4711 - val_loss: 0.4398\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 511us/step - loss: 0.4561 - val_loss: 0.4240\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 519us/step - loss: 0.4447 - val_loss: 0.4127\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 511us/step - loss: 0.4361 - val_loss: 0.4027\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 506us/step - loss: 0.4294 - val_loss: 0.3999\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 511us/step - loss: 0.4237 - val_loss: 0.3929\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 512us/step - loss: 0.4195 - val_loss: 0.3941\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 503us/step - loss: 0.4153 - val_loss: 0.3888\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.4118 - val_loss: 0.3961\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 517us/step - loss: 0.4089 - val_loss: 0.4040\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 514us/step - loss: 0.4059 - val_loss: 0.3843\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 514us/step - loss: 0.4033 - val_loss: 0.3878\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 514us/step - loss: 0.4008 - val_loss: 0.4195\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 514us/step - loss: 0.3988 - val_loss: 0.3909\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 505us/step - loss: 0.3966 - val_loss: 0.3971\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.3944 - val_loss: 0.3903\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.3924 - val_loss: 0.4069\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 521us/step - loss: 0.3909 - val_loss: 0.4134\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 514us/step - loss: 0.3891 - val_loss: 0.3990\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.3874 - val_loss: 0.3711\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 517us/step - loss: 0.3857 - val_loss: 0.3763\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 508us/step - loss: 0.3841 - val_loss: 0.3699\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 511us/step - loss: 0.3825 - val_loss: 0.3945\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e89a939b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 8396), started 1 day, 8:39:43 ago. (Use '!kill 8396' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c1a44f91065a765e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c1a44f91065a765e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac954974",
   "metadata": {},
   "source": [
    "## 10.2 신경망 하이퍼파라미터 튜닝하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c5d76210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b292cd05",
   "metadata": {},
   "source": [
    "사이킷런 regression estimator처럼 사용할 수 있게 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0d51dd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f3faef0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 0s 671us/step - loss: 1.1365 - val_loss: 26.0698\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 497us/step - loss: 0.8466 - val_loss: 33.1582\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 503us/step - loss: 0.7225 - val_loss: 1.5595\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 492us/step - loss: 0.4723 - val_loss: 0.5576\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 495us/step - loss: 0.4444 - val_loss: 0.4250\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 486us/step - loss: 0.4320 - val_loss: 0.4098\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 478us/step - loss: 0.4250 - val_loss: 0.4209\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 481us/step - loss: 0.4201 - val_loss: 0.4105\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 486us/step - loss: 0.4160 - val_loss: 0.4397\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 495us/step - loss: 0.4113 - val_loss: 0.4184\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 485us/step - loss: 0.4087 - val_loss: 0.3921\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 484us/step - loss: 0.4060 - val_loss: 0.3944\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 481us/step - loss: 0.4024 - val_loss: 0.4008\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 489us/step - loss: 0.4006 - val_loss: 0.4147\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 490us/step - loss: 0.3985 - val_loss: 0.3866\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 492us/step - loss: 0.3956 - val_loss: 0.3892\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 495us/step - loss: 0.3939 - val_loss: 0.4419\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 489us/step - loss: 0.3927 - val_loss: 0.3842\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 495us/step - loss: 0.3906 - val_loss: 0.4087\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 492us/step - loss: 0.3894 - val_loss: 0.4021\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 484us/step - loss: 0.3866 - val_loss: 0.3891\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 486us/step - loss: 0.3856 - val_loss: 0.3721\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 492us/step - loss: 0.3830 - val_loss: 0.3736\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 486us/step - loss: 0.3831 - val_loss: 0.4143\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 495us/step - loss: 0.3810 - val_loss: 0.3817\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 493us/step - loss: 0.3782 - val_loss: 0.3833\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 492us/step - loss: 0.3766 - val_loss: 0.4044\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 492us/step - loss: 0.3760 - val_loss: 0.4099\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 484us/step - loss: 0.3741 - val_loss: 0.3809\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 481us/step - loss: 0.3730 - val_loss: 0.3612\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 486us/step - loss: 0.3718 - val_loss: 0.3575\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 492us/step - loss: 0.3705 - val_loss: 0.4063\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 486us/step - loss: 0.3689 - val_loss: 0.3723\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 486us/step - loss: 0.3690 - val_loss: 0.3628\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 487us/step - loss: 0.3669 - val_loss: 0.3521\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 495us/step - loss: 0.3658 - val_loss: 0.3634\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 489us/step - loss: 0.3651 - val_loss: 0.3594\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 495us/step - loss: 0.3637 - val_loss: 0.3519\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 492us/step - loss: 0.3627 - val_loss: 0.3941\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 493us/step - loss: 0.3626 - val_loss: 0.3830\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 484us/step - loss: 0.3609 - val_loss: 0.3530\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 486us/step - loss: 0.3605 - val_loss: 0.3576\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 497us/step - loss: 0.3595 - val_loss: 0.3697\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 506us/step - loss: 0.3586 - val_loss: 0.3402\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 514us/step - loss: 0.3579 - val_loss: 0.3423\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 519us/step - loss: 0.3567 - val_loss: 0.3421\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 489us/step - loss: 0.3567 - val_loss: 0.3474\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 481us/step - loss: 0.3559 - val_loss: 0.3383\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 486us/step - loss: 0.3551 - val_loss: 0.3723\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 484us/step - loss: 0.3543 - val_loss: 0.3362\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 486us/step - loss: 0.3539 - val_loss: 0.3809\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 500us/step - loss: 0.3538 - val_loss: 0.3393\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 492us/step - loss: 0.3525 - val_loss: 0.3374\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 484us/step - loss: 0.3516 - val_loss: 0.3335\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 484us/step - loss: 0.3512 - val_loss: 0.4023\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 486us/step - loss: 0.3509 - val_loss: 0.3393\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 486us/step - loss: 0.3505 - val_loss: 0.3358\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 486us/step - loss: 0.3500 - val_loss: 0.5175\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 486us/step - loss: 0.3501 - val_loss: 0.3338\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 486us/step - loss: 0.3486 - val_loss: 0.3894\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 514us/step - loss: 0.3479 - val_loss: 0.3428\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 503us/step - loss: 0.3474 - val_loss: 0.3426\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 492us/step - loss: 0.3472 - val_loss: 0.3346\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 497us/step - loss: 0.3462 - val_loss: 0.3861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x214b57ba580>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "              validation_data=(X_valid, y_valid),\n",
    "              callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "54379c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 342us/step - loss: 0.3485\n"
     ]
    }
   ],
   "source": [
    "mse_test = keras_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "86a0cd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = keras_reg.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e0f86d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anpdi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 892us/step - loss: 2.8250 - val_loss: 3.9035\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 1.2097 - val_loss: 2.5509\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.8565 - val_loss: 1.0816\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 637us/step - loss: 0.7411 - val_loss: 0.7630\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.6946 - val_loss: 0.6634\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 652us/step - loss: 0.6664 - val_loss: 0.6277\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 627us/step - loss: 0.6442 - val_loss: 0.6070\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.6251 - val_loss: 0.5864\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 633us/step - loss: 0.6078 - val_loss: 0.5704\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.5918 - val_loss: 0.5565\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.5768 - val_loss: 0.5437\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.5633 - val_loss: 0.5286\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.5504 - val_loss: 0.5157\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.5384 - val_loss: 0.5043\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 652us/step - loss: 0.5271 - val_loss: 0.4949\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.5167 - val_loss: 0.4848\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 616us/step - loss: 0.5068 - val_loss: 0.4751\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.4976 - val_loss: 0.4669\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.4892 - val_loss: 0.4584\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 627us/step - loss: 0.4814 - val_loss: 0.4510\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.4741 - val_loss: 0.4439\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.4673 - val_loss: 0.4377\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.4612 - val_loss: 0.4326\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.4553 - val_loss: 0.4277\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.4500 - val_loss: 0.4218\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 660us/step - loss: 0.4451 - val_loss: 0.4208\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 621us/step - loss: 0.4406 - val_loss: 0.4141\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.4363 - val_loss: 0.4094\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.4325 - val_loss: 0.4088\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.4288 - val_loss: 0.4096\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.4254 - val_loss: 0.4057\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.4223 - val_loss: 0.4008\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.4193 - val_loss: 0.3981\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 632us/step - loss: 0.4166 - val_loss: 0.3917\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.4140 - val_loss: 0.3923\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.4117 - val_loss: 0.3904\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 627us/step - loss: 0.4093 - val_loss: 0.3877\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.4073 - val_loss: 0.3898\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.4053 - val_loss: 0.3941\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.4035 - val_loss: 0.3901\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.4016 - val_loss: 0.3888\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.3999 - val_loss: 0.3841\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.3983 - val_loss: 0.3851\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 652us/step - loss: 0.3967 - val_loss: 0.3822\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.3953 - val_loss: 0.3839\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.3939 - val_loss: 0.3800\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 625us/step - loss: 0.3924 - val_loss: 0.3759\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.3911 - val_loss: 0.3836\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.3897 - val_loss: 0.3783\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.3886 - val_loss: 0.3757\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.3874 - val_loss: 0.3754\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.3862 - val_loss: 0.3774\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.3851 - val_loss: 0.3780\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.3836 - val_loss: 0.3858\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.3829 - val_loss: 0.3776\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.3819 - val_loss: 0.3779\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.3809 - val_loss: 0.3892\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.3800 - val_loss: 0.3786\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.3790 - val_loss: 0.3889\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 627us/step - loss: 0.3780 - val_loss: 0.3827\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.3772 - val_loss: 0.3835\n",
      "121/121 [==============================] - 0s 333us/step - loss: 0.3918\n",
      "[CV] END learning_rate=0.0005235870662880465, n_hidden=2, n_neurons=76; total time=   9.5s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anpdi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 946us/step - loss: 2.9842 - val_loss: 7.2356\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 631us/step - loss: 1.2191 - val_loss: 9.4002\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.8806 - val_loss: 7.8098\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.7618 - val_loss: 5.8493\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 656us/step - loss: 0.7060 - val_loss: 4.3225\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.6721 - val_loss: 3.1403\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.6464 - val_loss: 2.2993\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.6241 - val_loss: 1.7397\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.6043 - val_loss: 1.2481\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.5858 - val_loss: 0.9401\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 627us/step - loss: 0.5688 - val_loss: 0.7594\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.5530 - val_loss: 0.6381\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 660us/step - loss: 0.5385 - val_loss: 0.5353\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.5251 - val_loss: 0.4997\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.5124 - val_loss: 0.4817\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 611us/step - loss: 0.5008 - val_loss: 0.4884\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.4903 - val_loss: 0.4957\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.4804 - val_loss: 0.5149\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.4714 - val_loss: 0.5372\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.4629 - val_loss: 0.5676\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.4556 - val_loss: 0.5642\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.4486 - val_loss: 0.5828\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.4424 - val_loss: 0.5843\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 598us/step - loss: 0.4365 - val_loss: 0.5745\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.4314 - val_loss: 0.5733\n",
      "121/121 [==============================] - 0s 367us/step - loss: 0.4388\n",
      "[CV] END learning_rate=0.0005235870662880465, n_hidden=2, n_neurons=76; total time=   4.3s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anpdi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 917us/step - loss: 3.1334 - val_loss: 2.0125\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 602us/step - loss: 1.2217 - val_loss: 1.1517\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.8771 - val_loss: 0.8706\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.7799 - val_loss: 0.7371\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.7311 - val_loss: 0.7010\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 652us/step - loss: 0.6958 - val_loss: 0.6649\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.6673 - val_loss: 0.6319\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 627us/step - loss: 0.6434 - val_loss: 0.6164\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.6218 - val_loss: 0.5846\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 652us/step - loss: 0.6031 - val_loss: 0.5817\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.5851 - val_loss: 0.5581\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.5697 - val_loss: 0.5593\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.5551 - val_loss: 0.5473\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 685us/step - loss: 0.5425 - val_loss: 0.5190\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.5311 - val_loss: 0.5257\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.5208 - val_loss: 0.5122\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 652us/step - loss: 0.5115 - val_loss: 0.5018\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.5031 - val_loss: 0.4990\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.4952 - val_loss: 0.4916\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.4881 - val_loss: 0.4908\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 633us/step - loss: 0.4817 - val_loss: 0.4769\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.4758 - val_loss: 0.4747\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 627us/step - loss: 0.4703 - val_loss: 0.4688\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.4653 - val_loss: 0.4631\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.4606 - val_loss: 0.4653\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.4561 - val_loss: 0.4661\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.4521 - val_loss: 0.4643\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.4482 - val_loss: 0.4517\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.4447 - val_loss: 0.4689\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 598us/step - loss: 0.4412 - val_loss: 0.4563\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.4380 - val_loss: 0.4703\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.4349 - val_loss: 0.4644\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.4323 - val_loss: 0.4405\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.4295 - val_loss: 0.4409\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.4269 - val_loss: 0.4526\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.4245 - val_loss: 0.4383\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 622us/step - loss: 0.4222 - val_loss: 0.4624\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.4200 - val_loss: 0.4398\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.4179 - val_loss: 0.4349\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.4157 - val_loss: 0.4616\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.4138 - val_loss: 0.4728\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.4121 - val_loss: 0.4709\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.4103 - val_loss: 0.4241\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.4084 - val_loss: 0.4213\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 603us/step - loss: 0.4067 - val_loss: 0.4555\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 616us/step - loss: 0.4052 - val_loss: 0.4349\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.4036 - val_loss: 0.4600\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 593us/step - loss: 0.4021 - val_loss: 0.4374\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.4009 - val_loss: 0.4080\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.3993 - val_loss: 0.4236\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.3976 - val_loss: 0.4064\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.3968 - val_loss: 0.4116\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.3950 - val_loss: 0.4483\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.3942 - val_loss: 0.4225\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 608us/step - loss: 0.3931 - val_loss: 0.4113\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.3917 - val_loss: 0.4361\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.3908 - val_loss: 0.4261\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.3897 - val_loss: 0.4303\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 598us/step - loss: 0.3885 - val_loss: 0.4392\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 627us/step - loss: 0.3876 - val_loss: 0.4183\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.3865 - val_loss: 0.4235\n",
      "121/121 [==============================] - 0s 358us/step - loss: 0.3879\n",
      "[CV] END learning_rate=0.0005235870662880465, n_hidden=2, n_neurons=76; total time=   9.5s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anpdi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 880us/step - loss: 8.5512 - val_loss: 7.6830\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 5.7944 - val_loss: 4.9304\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 4.0396 - val_loss: 3.2961\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 535us/step - loss: 2.9081 - val_loss: 2.3387\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 2.1683 - val_loss: 1.7670\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 535us/step - loss: 1.6764 - val_loss: 1.4297\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 1.3467 - val_loss: 1.2271\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 1.1226 - val_loss: 1.1094\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.9689 - val_loss: 1.0262\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.8623 - val_loss: 0.9937\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.7883 - val_loss: 0.9649\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.7361 - val_loss: 0.9519\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 535us/step - loss: 0.6989 - val_loss: 0.9526\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.6725 - val_loss: 0.9337\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.6531 - val_loss: 0.9228\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.6390 - val_loss: 0.9053\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.6283 - val_loss: 0.8961\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.6201 - val_loss: 0.8998\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.6138 - val_loss: 0.8847\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.6087 - val_loss: 0.8725\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.6045 - val_loss: 0.8746\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.6008 - val_loss: 0.8963\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.5980 - val_loss: 0.8793\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.5952 - val_loss: 0.8970\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.5930 - val_loss: 0.8892\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.5908 - val_loss: 0.8840\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.5888 - val_loss: 0.8843\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 517us/step - loss: 0.5867 - val_loss: 0.9006\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.5852 - val_loss: 0.8814\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.5834 - val_loss: 0.8666\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.5817 - val_loss: 0.8788\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.5802 - val_loss: 0.8712\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.5787 - val_loss: 0.8707\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.5772 - val_loss: 0.8567\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.5758 - val_loss: 0.8526\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.5744 - val_loss: 0.8562\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.5731 - val_loss: 0.8454\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.5719 - val_loss: 0.8365\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.5705 - val_loss: 0.8520\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.5693 - val_loss: 0.8409\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.5681 - val_loss: 0.8407\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.5669 - val_loss: 0.8526\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.5659 - val_loss: 0.8378\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.5647 - val_loss: 0.8487\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.5637 - val_loss: 0.8432\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 535us/step - loss: 0.5625 - val_loss: 0.8581\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.5615 - val_loss: 0.8704\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.5607 - val_loss: 0.8599\n",
      "121/121 [==============================] - 0s 333us/step - loss: 0.5603\n",
      "[CV] END learning_rate=0.00036385827571052293, n_hidden=0, n_neurons=25; total time=   6.5s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anpdi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 843us/step - loss: 4.5824 - val_loss: 7.8128\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 3.4246 - val_loss: 7.3823\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 2.6076 - val_loss: 7.2071\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 2.0308 - val_loss: 7.2121\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 1.6230 - val_loss: 7.3395\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 1.3336 - val_loss: 7.5501\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 1.1279 - val_loss: 7.8180\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.9813 - val_loss: 8.1277\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 600us/step - loss: 0.8764 - val_loss: 8.4572\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.8009 - val_loss: 8.8035\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.7463 - val_loss: 9.1596\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.7064 - val_loss: 9.5188\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.6770 - val_loss: 9.8773\n",
      "121/121 [==============================] - 0s 325us/step - loss: 0.8889\n",
      "[CV] END learning_rate=0.00036385827571052293, n_hidden=0, n_neurons=25; total time=   2.0s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anpdi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 774us/step - loss: 7.3223 - val_loss: 35.8407\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 5.0552 - val_loss: 21.2385\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 3.6475 - val_loss: 12.6353\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 2.7390 - val_loss: 7.6275\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 2.1333 - val_loss: 4.6907\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 1.7199 - val_loss: 2.9384\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 1.4322 - val_loss: 1.9425\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 1.2296 - val_loss: 1.3803\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 1.0847 - val_loss: 1.0589\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.9804 - val_loss: 0.8992\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.9046 - val_loss: 0.8176\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.8485 - val_loss: 0.7849\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.8068 - val_loss: 0.7785\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.7754 - val_loss: 0.7828\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.7514 - val_loss: 0.7931\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.7327 - val_loss: 0.8093\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.7180 - val_loss: 0.8184\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.7060 - val_loss: 0.8438\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 535us/step - loss: 0.6961 - val_loss: 0.8713\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.6880 - val_loss: 0.8918\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.6811 - val_loss: 0.8917\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.6748 - val_loss: 0.9135\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 579us/step - loss: 0.6696 - val_loss: 0.9023\n",
      "121/121 [==============================] - 0s 358us/step - loss: 0.6695\n",
      "[CV] END learning_rate=0.00036385827571052293, n_hidden=0, n_neurons=25; total time=   3.2s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anpdi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 780us/step - loss: 1.2112 - val_loss: 1531.3798\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 7.5216 - val_loss: 3128.6584\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 3.1613 - val_loss: 27620.7012\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 80.9298 - val_loss: 64231.9609\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 1591.0215 - val_loss: 187069.7969\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 133.9301 - val_loss: 511301.4688\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 29135.4141 - val_loss: 1441811.8750\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 3374.6270 - val_loss: 4346432.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 5902.3789 - val_loss: 12742476.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 105755.6406 - val_loss: 37202780.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 27645.7012 - val_loss: 115053696.0000\n",
      "121/121 [==============================] - 0s 333us/step - loss: 310072.0312\n",
      "[CV] END learning_rate=0.02407542200360601, n_hidden=0, n_neurons=85; total time=   1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anpdi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 760us/step - loss: 0.8485 - val_loss: 27.4108\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.5257 - val_loss: 8.8696\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.5143 - val_loss: 8.4015\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.5053 - val_loss: 27.1911\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.5114 - val_loss: 22.3268\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.5117 - val_loss: 8.3784\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.5169 - val_loss: 8.2054\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.5146 - val_loss: 10.9878\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.5152 - val_loss: 10.4827\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.5150 - val_loss: 8.9957\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.5078 - val_loss: 25.0933\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.5133 - val_loss: 20.7892\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.5131 - val_loss: 13.2974\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.5229 - val_loss: 12.7593\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.5105 - val_loss: 19.3235\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.5106 - val_loss: 14.3669\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.5194 - val_loss: 18.0023\n",
      "121/121 [==============================] - 0s 325us/step - loss: 0.9693\n",
      "[CV] END learning_rate=0.02407542200360601, n_hidden=0, n_neurons=85; total time=   2.5s\n",
      "Epoch 1/100\n",
      "  1/242 [..............................] - ETA: 37s - loss: 8.3382"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anpdi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 776us/step - loss: 1.6780 - val_loss: 0.5918\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 1.4162 - val_loss: 34.8864\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.6478 - val_loss: 0.7278\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 535us/step - loss: 0.9066 - val_loss: 386.1079\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 2.3438 - val_loss: 94.8444\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 535us/step - loss: 8.1052 - val_loss: 8.6551\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.6965 - val_loss: 0.9327\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 1.0099 - val_loss: 17.7424\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.5729 - val_loss: 2.7169\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.9662 - val_loss: 1.3491\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 1.1442 - val_loss: 617.9660\n",
      "121/121 [==============================] - 0s 308us/step - loss: 1.6253\n",
      "[CV] END learning_rate=0.02407542200360601, n_hidden=0, n_neurons=85; total time=   1.6s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anpdi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 813us/step - loss: 2.9828 - val_loss: 1.7659\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.8831 - val_loss: 0.8154\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.6757 - val_loss: 0.6184\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.6313 - val_loss: 0.6621\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.6033 - val_loss: 0.5560\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.5829 - val_loss: 0.5591\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.5651 - val_loss: 0.5410\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.5489 - val_loss: 0.5138\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.5362 - val_loss: 0.4976\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.5235 - val_loss: 0.4864\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.5128 - val_loss: 0.4916\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.5023 - val_loss: 0.4960\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 574us/step - loss: 0.4929 - val_loss: 0.4599\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.4857 - val_loss: 0.4801\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.4778 - val_loss: 0.4560\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.4712 - val_loss: 0.4708\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.4649 - val_loss: 0.4332\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.4598 - val_loss: 0.4606\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.4544 - val_loss: 0.4300\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.4496 - val_loss: 0.4218\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.4456 - val_loss: 0.4273\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.4413 - val_loss: 0.4340\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.4376 - val_loss: 0.4219\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.4339 - val_loss: 0.4246\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.4309 - val_loss: 0.4225\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.4279 - val_loss: 0.4236\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.4249 - val_loss: 0.4215\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.4221 - val_loss: 0.4054\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.4196 - val_loss: 0.4060\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.4170 - val_loss: 0.4163\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.4151 - val_loss: 0.4228\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.4125 - val_loss: 0.4153\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.4107 - val_loss: 0.4247\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.4087 - val_loss: 0.3903\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.4067 - val_loss: 0.4051\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.4046 - val_loss: 0.4132\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.4030 - val_loss: 0.3996\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.4012 - val_loss: 0.4032\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.3995 - val_loss: 0.4138\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.3982 - val_loss: 0.3836\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 598us/step - loss: 0.3964 - val_loss: 0.4014\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3950 - val_loss: 0.3840\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.3937 - val_loss: 0.3946\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3924 - val_loss: 0.3816\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.3911 - val_loss: 0.3825\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.3899 - val_loss: 0.3776\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.3887 - val_loss: 0.3781\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.3875 - val_loss: 0.3727\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.3865 - val_loss: 0.3832\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.3854 - val_loss: 0.4040\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.3845 - val_loss: 0.4052\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.3835 - val_loss: 0.3966\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.3826 - val_loss: 0.3807\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 566us/step - loss: 0.3816 - val_loss: 0.3974\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.3809 - val_loss: 0.3678\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.3800 - val_loss: 0.3709\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.3791 - val_loss: 0.4046\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.3784 - val_loss: 0.3976\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3775 - val_loss: 0.3964\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.3769 - val_loss: 0.3734\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.3761 - val_loss: 0.3985\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.3755 - val_loss: 0.3900\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.3748 - val_loss: 0.3595\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.3741 - val_loss: 0.3820\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3733 - val_loss: 0.3956\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.3727 - val_loss: 0.3919\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.3720 - val_loss: 0.3920\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.3717 - val_loss: 0.3670\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3708 - val_loss: 0.3929\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3703 - val_loss: 0.3767\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.3695 - val_loss: 0.3737\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3690 - val_loss: 0.3573\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.3684 - val_loss: 0.4012\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.3680 - val_loss: 0.3654\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.3674 - val_loss: 0.3753\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.3666 - val_loss: 0.3898\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.3666 - val_loss: 0.3537\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.3657 - val_loss: 0.3599\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3654 - val_loss: 0.3851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.3649 - val_loss: 0.3883\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3645 - val_loss: 0.3493\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.3639 - val_loss: 0.3635\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.3634 - val_loss: 0.3596\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.3631 - val_loss: 0.3537\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.3625 - val_loss: 0.3836\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.3622 - val_loss: 0.3774\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.3617 - val_loss: 0.3842\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.3614 - val_loss: 0.3779\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.3609 - val_loss: 0.3535\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.3605 - val_loss: 0.3533\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3600 - val_loss: 0.3542\n",
      "121/121 [==============================] - 0s 325us/step - loss: 0.3735\n",
      "[CV] END learning_rate=0.0010080809905466269, n_hidden=1, n_neurons=75; total time=  12.7s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anpdi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 830us/step - loss: 2.4582 - val_loss: 1.6594\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.8291 - val_loss: 1.1376\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.7120 - val_loss: 0.7346\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.6713 - val_loss: 0.6322\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.6417 - val_loss: 0.7002\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.6162 - val_loss: 0.8676\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.5936 - val_loss: 1.0700\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.5733 - val_loss: 1.3031\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.5552 - val_loss: 1.4809\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.5392 - val_loss: 1.7282\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.5246 - val_loss: 1.8396\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.5120 - val_loss: 2.0178\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.5005 - val_loss: 2.1320\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.4902 - val_loss: 2.2284\n",
      "121/121 [==============================] - 0s 342us/step - loss: 0.5354\n",
      "[CV] END learning_rate=0.0010080809905466269, n_hidden=1, n_neurons=75; total time=   2.2s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anpdi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 818us/step - loss: 2.5187 - val_loss: 9.2668\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 1.0909 - val_loss: 0.8745\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.7770 - val_loss: 0.7840\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.7058 - val_loss: 0.6732\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.6671 - val_loss: 0.6325\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.6389 - val_loss: 0.6062\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.6154 - val_loss: 0.6010\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.5945 - val_loss: 0.5641\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.5769 - val_loss: 0.5501\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.5599 - val_loss: 0.5330\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.5460 - val_loss: 0.5298\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.5326 - val_loss: 0.5429\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.5210 - val_loss: 0.4966\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.5109 - val_loss: 0.4999\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.5013 - val_loss: 0.4778\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.4927 - val_loss: 0.4664\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.4850 - val_loss: 0.4533\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.4781 - val_loss: 0.4612\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.4722 - val_loss: 0.4427\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.4668 - val_loss: 0.4353\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.4617 - val_loss: 0.4526\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.4569 - val_loss: 0.4391\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.4529 - val_loss: 0.4303\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.4490 - val_loss: 0.4286\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.4455 - val_loss: 0.4147\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.4423 - val_loss: 0.4298\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 596us/step - loss: 0.4393 - val_loss: 0.4268\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.4367 - val_loss: 0.4210\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.4342 - val_loss: 0.4043\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.4319 - val_loss: 0.4207\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.4296 - val_loss: 0.4181\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.4275 - val_loss: 0.4158\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.4254 - val_loss: 0.4396\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.4240 - val_loss: 0.3981\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.4221 - val_loss: 0.4043\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.4204 - val_loss: 0.4175\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.4189 - val_loss: 0.3895\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.4175 - val_loss: 0.4047\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.4160 - val_loss: 0.3956\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 562us/step - loss: 0.4148 - val_loss: 0.3915\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.4134 - val_loss: 0.3878\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.4119 - val_loss: 0.4088\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.4110 - val_loss: 0.3940\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.4099 - val_loss: 0.3805\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.4083 - val_loss: 0.4412\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.4079 - val_loss: 0.3776\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.4062 - val_loss: 0.4323\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.4056 - val_loss: 0.4183\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.4046 - val_loss: 0.4137\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.4036 - val_loss: 0.3741\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.4025 - val_loss: 0.3804\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.4012 - val_loss: 0.4288\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.4011 - val_loss: 0.3755\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.3997 - val_loss: 0.3949\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3993 - val_loss: 0.3821\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3982 - val_loss: 0.3983\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.3975 - val_loss: 0.3843\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.3968 - val_loss: 0.3815\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3956 - val_loss: 0.4054\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 554us/step - loss: 0.3954 - val_loss: 0.3834\n",
      "121/121 [==============================] - 0s 325us/step - loss: 0.3934\n",
      "[CV] END learning_rate=0.0010080809905466269, n_hidden=1, n_neurons=75; total time=   8.6s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anpdi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 847us/step - loss: 1.1671 - val_loss: 4.6712\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.7388 - val_loss: 23.7102\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.6984 - val_loss: 4.7314\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.5346 - val_loss: 0.5076\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.4520 - val_loss: 0.4572\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 561us/step - loss: 0.4374 - val_loss: 0.4145\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.4271 - val_loss: 0.3980\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.4189 - val_loss: 0.3877\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.4124 - val_loss: 0.3833\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.4071 - val_loss: 0.3775\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.4026 - val_loss: 0.3813\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.3992 - val_loss: 0.3824\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.3949 - val_loss: 0.3786\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 550us/step - loss: 0.3913 - val_loss: 0.3939\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.3882 - val_loss: 0.3888\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.3849 - val_loss: 0.3950\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.3828 - val_loss: 0.3833\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.3803 - val_loss: 0.3908\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.3788 - val_loss: 0.3834\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.3774 - val_loss: 0.3826\n",
      "121/121 [==============================] - 0s 317us/step - loss: 0.3920\n",
      "[CV] END learning_rate=0.005066194105744595, n_hidden=1, n_neurons=40; total time=   3.2s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anpdi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 901us/step - loss: 1.0707 - val_loss: 1.8013\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 535us/step - loss: 0.5732 - val_loss: 0.6113\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.5000 - val_loss: 0.4529\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.4603 - val_loss: 0.4856\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 529us/step - loss: 0.4393 - val_loss: 0.4820\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.4240 - val_loss: 0.4362\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.4158 - val_loss: 0.4030\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.4091 - val_loss: 0.3819\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.4038 - val_loss: 0.3835\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.3993 - val_loss: 0.4010\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.3950 - val_loss: 0.4324\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.3918 - val_loss: 0.5092\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.3894 - val_loss: 0.5697\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 535us/step - loss: 0.3857 - val_loss: 0.6202\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.3839 - val_loss: 0.6973\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.3809 - val_loss: 0.7634\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.3789 - val_loss: 0.7942\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.3755 - val_loss: 0.8847\n",
      "121/121 [==============================] - 0s 317us/step - loss: 0.3994\n",
      "[CV] END learning_rate=0.005066194105744595, n_hidden=1, n_neurons=40; total time=   2.6s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anpdi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 863us/step - loss: 1.2144 - val_loss: 15.1987\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.7584 - val_loss: 23.4356\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 535us/step - loss: 0.8264 - val_loss: 2.8614\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.5505 - val_loss: 0.5135\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.4751 - val_loss: 0.4330\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.4486 - val_loss: 0.4005\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 536us/step - loss: 0.4352 - val_loss: 0.4118\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.4278 - val_loss: 0.3928\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.4171 - val_loss: 0.3927\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.4169 - val_loss: 0.3983\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.4117 - val_loss: 0.3939\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.4022 - val_loss: 0.3959\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.4001 - val_loss: 0.3955\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.4029 - val_loss: 0.3943\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.3931 - val_loss: 0.3921\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.3931 - val_loss: 0.3915\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.3913 - val_loss: 0.3873\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3865 - val_loss: 0.3947\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.3843 - val_loss: 0.3905\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.3813 - val_loss: 0.3893\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.3814 - val_loss: 0.3904\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.3824 - val_loss: 0.3932\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.3753 - val_loss: 0.3910\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.3754 - val_loss: 0.3853\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 0.3739 - val_loss: 0.3869\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 0.3721 - val_loss: 0.3854\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.3727 - val_loss: 0.3845\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 535us/step - loss: 0.3691 - val_loss: 0.3855\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.3685 - val_loss: 0.3823\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.3674 - val_loss: 0.3755\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.3655 - val_loss: 0.3757\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.3651 - val_loss: 0.3784\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 0.3648 - val_loss: 0.3716\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.3630 - val_loss: 0.3733\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.3614 - val_loss: 0.3804\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.3608 - val_loss: 0.3705\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.3622 - val_loss: 0.3665\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.3585 - val_loss: 0.3703\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.3575 - val_loss: 0.3708\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.3586 - val_loss: 0.3691\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.3772 - val_loss: 0.3654\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.3663 - val_loss: 0.3665\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 0.3587 - val_loss: 0.3690\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.3542 - val_loss: 0.3658\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.3559 - val_loss: 0.3603\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.3542 - val_loss: 0.3591\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.3536 - val_loss: 0.3590\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 535us/step - loss: 0.3526 - val_loss: 0.3582\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.3539 - val_loss: 0.3614\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.3558 - val_loss: 0.3588\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.3496 - val_loss: 0.3538\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.3524 - val_loss: 0.3583\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.3510 - val_loss: 0.3599\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.3488 - val_loss: 0.3561\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.3482 - val_loss: 0.3620\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.3578 - val_loss: 0.3658\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.3552 - val_loss: 0.3618\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.3490 - val_loss: 0.3602\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.3490 - val_loss: 0.4007\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.3474 - val_loss: 0.3596\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.3463 - val_loss: 0.3613\n",
      "121/121 [==============================] - 0s 325us/step - loss: 0.3450\n",
      "[CV] END learning_rate=0.005066194105744595, n_hidden=1, n_neurons=40; total time=   8.1s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anpdi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 867us/step - loss: 2.2495 - val_loss: 0.9723\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.6868 - val_loss: 0.5988\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.5691 - val_loss: 0.5268\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.5294 - val_loss: 0.5047\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 598us/step - loss: 0.5086 - val_loss: 0.5073\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.4945 - val_loss: 0.4966\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.4842 - val_loss: 0.4950\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.4765 - val_loss: 0.4937\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.4693 - val_loss: 0.5016\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.4635 - val_loss: 0.4934\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.4583 - val_loss: 0.4831\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.4532 - val_loss: 0.4747\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.4489 - val_loss: 0.4774\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.4447 - val_loss: 0.4702\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 593us/step - loss: 0.4407 - val_loss: 0.4670\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 593us/step - loss: 0.4368 - val_loss: 0.4664\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.4329 - val_loss: 0.4553\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.4298 - val_loss: 0.4518\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 572us/step - loss: 0.4261 - val_loss: 0.4573\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.4229 - val_loss: 0.4481\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.4196 - val_loss: 0.4457\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.4171 - val_loss: 0.4435\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.4141 - val_loss: 0.4397\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.4118 - val_loss: 0.4419\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.4090 - val_loss: 0.4458\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.4060 - val_loss: 0.4332\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.4038 - val_loss: 0.4297\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.4018 - val_loss: 0.4301\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.3997 - val_loss: 0.4261\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.3977 - val_loss: 0.4269\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.3960 - val_loss: 0.4214\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3944 - val_loss: 0.4205\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.3928 - val_loss: 0.4263\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.3914 - val_loss: 0.4143\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.3901 - val_loss: 0.4057\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.3888 - val_loss: 0.4074\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.3875 - val_loss: 0.4122\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.3862 - val_loss: 0.4133\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.3850 - val_loss: 0.4064\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.3838 - val_loss: 0.3969\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.3826 - val_loss: 0.4003\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.3818 - val_loss: 0.3984\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.3804 - val_loss: 0.4058\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.3798 - val_loss: 0.4038\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.3787 - val_loss: 0.4052\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.3779 - val_loss: 0.3978\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3771 - val_loss: 0.3989\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.3756 - val_loss: 0.4014\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.3754 - val_loss: 0.3910\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.3742 - val_loss: 0.3885\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.3740 - val_loss: 0.3897\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.3730 - val_loss: 0.3911\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.3721 - val_loss: 0.3879\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3717 - val_loss: 0.3989\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 558us/step - loss: 0.3708 - val_loss: 0.3865\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.3699 - val_loss: 0.3918\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3700 - val_loss: 0.3900\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.3691 - val_loss: 0.3855\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.3688 - val_loss: 0.3902\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3679 - val_loss: 0.3970\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.3676 - val_loss: 0.3888\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3668 - val_loss: 0.3928\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3662 - val_loss: 0.3887\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.3657 - val_loss: 0.3850\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.3655 - val_loss: 0.3925\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.3648 - val_loss: 0.3880\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.3643 - val_loss: 0.3832\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3638 - val_loss: 0.3879\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.3634 - val_loss: 0.3789\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.3629 - val_loss: 0.3887\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.3622 - val_loss: 0.3794\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.3620 - val_loss: 0.3918\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.3618 - val_loss: 0.3757\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 598us/step - loss: 0.3614 - val_loss: 0.3845\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.3605 - val_loss: 0.3870\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3606 - val_loss: 0.3822\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3599 - val_loss: 0.3791\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.3596 - val_loss: 0.3778\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.3592 - val_loss: 0.3833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.3586 - val_loss: 0.3765\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.3585 - val_loss: 0.3733\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.3580 - val_loss: 0.3769\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.3578 - val_loss: 0.3769\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.3574 - val_loss: 0.3737\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.3570 - val_loss: 0.3739\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.3567 - val_loss: 0.3779\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3560 - val_loss: 0.3701\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.3559 - val_loss: 0.3654\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.3556 - val_loss: 0.3676\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 0.3552 - val_loss: 0.3762\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.3550 - val_loss: 0.3737\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 615us/step - loss: 0.3545 - val_loss: 0.3707\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 0.3542 - val_loss: 0.3684\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.3540 - val_loss: 0.3706\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.3533 - val_loss: 0.3733\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 654us/step - loss: 0.3532 - val_loss: 0.3670\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 681us/step - loss: 0.3528 - val_loss: 0.3664\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.3524 - val_loss: 0.3698\n",
      "121/121 [==============================] - 0s 467us/step - loss: 0.3703\n",
      "[CV] END learning_rate=0.0012837467543940191, n_hidden=3, n_neurons=11; total time=  14.1s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anpdi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 984us/step - loss: 3.0174 - val_loss: 2.4487\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 627us/step - loss: 1.2077 - val_loss: 2.2284\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.9354 - val_loss: 1.6253\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.8013 - val_loss: 1.1031\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.7399 - val_loss: 0.7754\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.7032 - val_loss: 0.6520\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 695us/step - loss: 0.6728 - val_loss: 0.6695\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 660us/step - loss: 0.6458 - val_loss: 0.7157\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.6202 - val_loss: 0.7952\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.5968 - val_loss: 0.8294\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 616us/step - loss: 0.5746 - val_loss: 0.8430\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.5533 - val_loss: 0.8678\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.5335 - val_loss: 0.8956\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 660us/step - loss: 0.5154 - val_loss: 0.9166\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.5000 - val_loss: 0.9356\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.4866 - val_loss: 0.9547\n",
      "121/121 [==============================] - 0s 358us/step - loss: 0.5117\n",
      "[CV] END learning_rate=0.0012837467543940191, n_hidden=3, n_neurons=11; total time=   2.8s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anpdi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 963us/step - loss: 2.2243 - val_loss: 4.8490\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 583us/step - loss: 0.9261 - val_loss: 1.7273\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.7293 - val_loss: 1.3041\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.6714 - val_loss: 0.9773\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 656us/step - loss: 0.6397 - val_loss: 0.8356\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.6134 - val_loss: 0.7384\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 583us/step - loss: 0.5908 - val_loss: 0.6601\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.5676 - val_loss: 0.5969\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 652us/step - loss: 0.5472 - val_loss: 0.5679\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.5275 - val_loss: 0.5302\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.5102 - val_loss: 0.4984\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.4945 - val_loss: 0.4783\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.4807 - val_loss: 0.4610\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 593us/step - loss: 0.4685 - val_loss: 0.4459\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.4581 - val_loss: 0.4373\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.4485 - val_loss: 0.4267\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 652us/step - loss: 0.4410 - val_loss: 0.4203\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.4345 - val_loss: 0.4153\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.4295 - val_loss: 0.4100\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.4249 - val_loss: 0.4062\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.4214 - val_loss: 0.4064\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 613us/step - loss: 0.4175 - val_loss: 0.4064\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 714us/step - loss: 0.4152 - val_loss: 0.4045\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 656us/step - loss: 0.4129 - val_loss: 0.4021\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 652us/step - loss: 0.4103 - val_loss: 0.4021\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.4082 - val_loss: 0.4013\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 627us/step - loss: 0.4070 - val_loss: 0.4001\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.4054 - val_loss: 0.4000\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.4038 - val_loss: 0.3985\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.4026 - val_loss: 0.4006\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.4014 - val_loss: 0.4022\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.4001 - val_loss: 0.3997\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.3989 - val_loss: 0.4027\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 660us/step - loss: 0.3981 - val_loss: 0.4018\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 627us/step - loss: 0.3972 - val_loss: 0.3998\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 650us/step - loss: 0.3961 - val_loss: 0.4000\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.3950 - val_loss: 0.4015\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 656us/step - loss: 0.3942 - val_loss: 0.4046\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.3935 - val_loss: 0.4036\n",
      "121/121 [==============================] - 0s 367us/step - loss: 0.3857\n",
      "[CV] END learning_rate=0.0012837467543940191, n_hidden=3, n_neurons=11; total time=   6.5s\n",
      "Epoch 1/100\n",
      "  1/242 [..............................] - ETA: 37s - loss: 8.4573"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anpdi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 863us/step - loss: 1.6279 - val_loss: 18.6475\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 1.0107 - val_loss: 60.4413\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 593us/step - loss: 0.8430 - val_loss: 67.2112\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 1.2474 - val_loss: 269.7464\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 531us/step - loss: 2.7643 - val_loss: 624.2971\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 10.2994 - val_loss: 1544.4521\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 593us/step - loss: 16.5714 - val_loss: 3567.5869\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 45.7895 - val_loss: 8959.7529\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 56.9785 - val_loss: 21144.0684\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 535us/step - loss: 374.2615 - val_loss: 51967.7188\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 531us/step - loss: 294.9300 - val_loss: 127926.2891\n",
      "121/121 [==============================] - 0s 325us/step - loss: 358.8185\n",
      "[CV] END learning_rate=0.006251289133268363, n_hidden=0, n_neurons=32; total time=   1.7s\n",
      "Epoch 1/100\n",
      "  1/242 [..............................] - ETA: 37s - loss: 6.3172"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anpdi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 784us/step - loss: 1.7770 - val_loss: 29.9460\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.6225 - val_loss: 28.4227\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.5785 - val_loss: 25.5805\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.5520 - val_loss: 25.3184\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.5348 - val_loss: 21.8082\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.5235 - val_loss: 20.5731\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.5165 - val_loss: 18.9246\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.5100 - val_loss: 19.4929\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.5085 - val_loss: 19.6465\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.5064 - val_loss: 19.7748\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 0.5044 - val_loss: 20.4145\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.5033 - val_loss: 21.4183\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 523us/step - loss: 0.5031 - val_loss: 20.4217\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 0.5028 - val_loss: 20.2339\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 531us/step - loss: 0.5019 - val_loss: 19.0738\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.5016 - val_loss: 19.1554\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.5014 - val_loss: 19.1169\n",
      "121/121 [==============================] - 0s 308us/step - loss: 0.9599\n",
      "[CV] END learning_rate=0.006251289133268363, n_hidden=0, n_neurons=32; total time=   2.4s\n",
      "Epoch 1/100\n",
      "  1/242 [..............................] - ETA: 37s - loss: 6.8425"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anpdi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 768us/step - loss: 1.8415 - val_loss: 3.2217\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 0.6861 - val_loss: 15.2181\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 0.6792 - val_loss: 35.6258\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 0.8109 - val_loss: 131.4839\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 519us/step - loss: 0.9593 - val_loss: 90.9305\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 506us/step - loss: 1.0490 - val_loss: 226.3184\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 510us/step - loss: 4.5467 - val_loss: 393.4521\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 515us/step - loss: 9.3245 - val_loss: 521.2675\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 502us/step - loss: 3.0035 - val_loss: 687.4807\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 494us/step - loss: 11.0753 - val_loss: 1075.6411\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 527us/step - loss: 7.2842 - val_loss: 1567.5062\n",
      "121/121 [==============================] - 0s 325us/step - loss: 1.5655\n",
      "[CV] END learning_rate=0.006251289133268363, n_hidden=0, n_neurons=32; total time=   1.6s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anpdi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 867us/step - loss: 4.1664 - val_loss: 2.9894\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 2.4986 - val_loss: 1.9842\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 1.8132 - val_loss: 1.5791\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 578us/step - loss: 1.5326 - val_loss: 1.4171\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 1.4169 - val_loss: 1.3523\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 1.3691 - val_loss: 1.3280\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 1.3496 - val_loss: 1.3187\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 1.3414 - val_loss: 1.3156\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 1.3381 - val_loss: 1.3149\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 1.3368 - val_loss: 1.3149\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 1.3362 - val_loss: 1.3150\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 1.3360 - val_loss: 1.3152\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 1.3359 - val_loss: 1.3153\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 1.3359 - val_loss: 1.3155\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 1.3358 - val_loss: 1.3156\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 1.3358 - val_loss: 1.3156\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 1.3358 - val_loss: 1.3157\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 1.3358 - val_loss: 1.3157\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 1.3358 - val_loss: 1.3157\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 1.3358 - val_loss: 1.3158\n",
      "121/121 [==============================] - 0s 333us/step - loss: 1.3501\n",
      "[CV] END learning_rate=0.0009172223568843883, n_hidden=3, n_neurons=1; total time=   3.0s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anpdi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 855us/step - loss: 4.2375 - val_loss: 2.9664\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 2.5343 - val_loss: 1.9628\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 1.8354 - val_loss: 1.5624\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 556us/step - loss: 1.5481 - val_loss: 1.4052\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 1.4299 - val_loss: 1.3450\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 540us/step - loss: 1.3814 - val_loss: 1.3235\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 1.3615 - val_loss: 1.3165\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 1.3532 - val_loss: 1.3149\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 544us/step - loss: 1.3498 - val_loss: 1.3150\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 531us/step - loss: 1.3484 - val_loss: 1.3156\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 1.3478 - val_loss: 1.3161\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 1.3476 - val_loss: 1.3165\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 1.3475 - val_loss: 1.3168\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 565us/step - loss: 1.3474 - val_loss: 1.3170\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 1.3474 - val_loss: 1.3171\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 1.3474 - val_loss: 1.3173\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 1.3474 - val_loss: 1.3175\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 623us/step - loss: 1.3474 - val_loss: 1.3175\n",
      "121/121 [==============================] - 0s 342us/step - loss: 1.3262\n",
      "[CV] END learning_rate=0.0009172223568843883, n_hidden=3, n_neurons=1; total time=   2.8s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anpdi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 859us/step - loss: 4.2501 - val_loss: 2.9648\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 2.5349 - val_loss: 1.9573\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 1.8291 - val_loss: 1.5576\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 1.5398 - val_loss: 1.4018\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 1.4204 - val_loss: 1.3428\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 1.3715 - val_loss: 1.3223\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 548us/step - loss: 1.3515 - val_loss: 1.3160\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 1.3431 - val_loss: 1.3148\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 1.3397 - val_loss: 1.3152\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 1.3383 - val_loss: 1.3160\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 560us/step - loss: 1.3377 - val_loss: 1.3167\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 1.3375 - val_loss: 1.3172\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 552us/step - loss: 1.3374 - val_loss: 1.3176\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 1.3373 - val_loss: 1.3179\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 1.3373 - val_loss: 1.3180\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 1.3373 - val_loss: 1.3181\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 656us/step - loss: 1.3373 - val_loss: 1.3183\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 593us/step - loss: 1.3373 - val_loss: 1.3183\n",
      "121/121 [==============================] - 0s 408us/step - loss: 1.3467\n",
      "[CV] END learning_rate=0.0009172223568843883, n_hidden=3, n_neurons=1; total time=   3.1s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anpdi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 2.3588 - val_loss: 5.0707\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.9502 - val_loss: 1.1761\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.7891 - val_loss: 0.7574\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 594us/step - loss: 0.7174 - val_loss: 0.6599\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 633us/step - loss: 0.6701 - val_loss: 0.6172\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.6333 - val_loss: 0.5893\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 652us/step - loss: 0.6019 - val_loss: 0.5602\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.5738 - val_loss: 0.5392\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 598us/step - loss: 0.5483 - val_loss: 0.5107\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 639us/step - loss: 0.5258 - val_loss: 0.4895\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.5064 - val_loss: 0.4688\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.4900 - val_loss: 0.4546\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.4759 - val_loss: 0.4412\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.4637 - val_loss: 0.4314\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.4529 - val_loss: 0.4223\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 598us/step - loss: 0.4436 - val_loss: 0.4142\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.4353 - val_loss: 0.4076\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.4282 - val_loss: 0.4036\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.4210 - val_loss: 0.4031\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.4153 - val_loss: 0.3925\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.4096 - val_loss: 0.3928\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.4044 - val_loss: 0.3824\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 593us/step - loss: 0.3991 - val_loss: 0.3824\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.3954 - val_loss: 0.3816\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.3909 - val_loss: 0.3742\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.3871 - val_loss: 0.3766\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 636us/step - loss: 0.3836 - val_loss: 0.3654\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.3803 - val_loss: 0.3664\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.3767 - val_loss: 0.3642\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.3744 - val_loss: 0.3678\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.3718 - val_loss: 0.3632\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.3695 - val_loss: 0.3572\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 605us/step - loss: 0.3672 - val_loss: 0.3539\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.3647 - val_loss: 0.3557\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.3629 - val_loss: 0.3521\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 644us/step - loss: 0.3613 - val_loss: 0.3495\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.3592 - val_loss: 0.3481\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 598us/step - loss: 0.3574 - val_loss: 0.3533\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 647us/step - loss: 0.3560 - val_loss: 0.3478\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.3538 - val_loss: 0.3524\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.3532 - val_loss: 0.3498\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 629us/step - loss: 0.3516 - val_loss: 0.3424\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.3504 - val_loss: 0.3409\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 627us/step - loss: 0.3487 - val_loss: 0.3488\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.3482 - val_loss: 0.3408\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.3469 - val_loss: 0.3395\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.3459 - val_loss: 0.3410\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.3450 - val_loss: 0.3388\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.3440 - val_loss: 0.3375\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.3433 - val_loss: 0.3415\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.3423 - val_loss: 0.3359\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.3414 - val_loss: 0.3389\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 593us/step - loss: 0.3403 - val_loss: 0.3361\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 593us/step - loss: 0.3398 - val_loss: 0.3346\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 625us/step - loss: 0.3395 - val_loss: 0.3403\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.3382 - val_loss: 0.3344\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.3376 - val_loss: 0.3331\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 593us/step - loss: 0.3369 - val_loss: 0.3397\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.3363 - val_loss: 0.3319\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 594us/step - loss: 0.3355 - val_loss: 0.3308\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.3353 - val_loss: 0.3313\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 604us/step - loss: 0.3346 - val_loss: 0.3303\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 659us/step - loss: 0.3337 - val_loss: 0.3319\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.3336 - val_loss: 0.3392\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.3326 - val_loss: 0.3286\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.3318 - val_loss: 0.3277\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.3309 - val_loss: 0.3343\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.3307 - val_loss: 0.3273\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.3299 - val_loss: 0.3262\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.3297 - val_loss: 0.3322\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.3290 - val_loss: 0.3252\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 621us/step - loss: 0.3285 - val_loss: 0.3268\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.3277 - val_loss: 0.3253\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.3271 - val_loss: 0.3269\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.3270 - val_loss: 0.3256\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.3262 - val_loss: 0.3266\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.3262 - val_loss: 0.3236\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.3254 - val_loss: 0.3287\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.3250 - val_loss: 0.3247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 569us/step - loss: 0.3244 - val_loss: 0.3217\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.3240 - val_loss: 0.3405\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 571us/step - loss: 0.3236 - val_loss: 0.3261\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.3234 - val_loss: 0.3417\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.3232 - val_loss: 0.3218\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.3222 - val_loss: 0.3367\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.3220 - val_loss: 0.3259\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.3214 - val_loss: 0.3242\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.3211 - val_loss: 0.3264\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.3208 - val_loss: 0.3274\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 564us/step - loss: 0.3204 - val_loss: 0.3271\n",
      "121/121 [==============================] - 0s 325us/step - loss: 0.3475\n",
      "[CV] END learning_rate=0.0011587711178708176, n_hidden=3, n_neurons=40; total time=  13.6s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anpdi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 967us/step - loss: 2.4786 - val_loss: 17.3316\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 669us/step - loss: 1.0183 - val_loss: 8.2650\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.7528 - val_loss: 3.8493\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.6661 - val_loss: 1.7424\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.6206 - val_loss: 0.7399\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 635us/step - loss: 0.5873 - val_loss: 0.5360\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.5595 - val_loss: 0.6005\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 689us/step - loss: 0.5357 - val_loss: 0.7386\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 652us/step - loss: 0.5147 - val_loss: 0.8166\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.4965 - val_loss: 0.8463\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.4806 - val_loss: 0.8554\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.4659 - val_loss: 0.8670\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 631us/step - loss: 0.4541 - val_loss: 0.8693\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 697us/step - loss: 0.4440 - val_loss: 0.8071\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 739us/step - loss: 0.4348 - val_loss: 0.7690\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 714us/step - loss: 0.4269 - val_loss: 0.7444\n",
      "121/121 [==============================] - 0s 333us/step - loss: 0.4523\n",
      "[CV] END learning_rate=0.0011587711178708176, n_hidden=3, n_neurons=40; total time=   2.9s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anpdi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 938us/step - loss: 2.3897 - val_loss: 2.7555\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.7673 - val_loss: 0.6885\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.6456 - val_loss: 0.6699\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 677us/step - loss: 0.6108 - val_loss: 0.7890\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 660us/step - loss: 0.5801 - val_loss: 0.7240\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.5626 - val_loss: 0.7514\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 660us/step - loss: 0.5399 - val_loss: 0.5121\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.5231 - val_loss: 0.4917\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 627us/step - loss: 0.5073 - val_loss: 0.4873\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.4941 - val_loss: 0.5417\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 689us/step - loss: 0.4822 - val_loss: 0.4694\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 660us/step - loss: 0.4727 - val_loss: 0.4867\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.4623 - val_loss: 0.4345\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 643us/step - loss: 0.4538 - val_loss: 0.4521\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 616us/step - loss: 0.4459 - val_loss: 0.4435\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.4387 - val_loss: 0.4142\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.4327 - val_loss: 0.4757\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.4265 - val_loss: 0.4082\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.4206 - val_loss: 0.4110\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 627us/step - loss: 0.4162 - val_loss: 0.3934\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 623us/step - loss: 0.4109 - val_loss: 0.4114\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.4084 - val_loss: 0.3931\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.4032 - val_loss: 0.4822\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.3996 - val_loss: 0.4100\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.3964 - val_loss: 0.3825\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.3922 - val_loss: 0.3961\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 615us/step - loss: 0.3895 - val_loss: 0.3724\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.3865 - val_loss: 0.4006\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.3838 - val_loss: 0.3644\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.3806 - val_loss: 0.4262\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 613us/step - loss: 0.3789 - val_loss: 0.3872\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.3763 - val_loss: 0.3896\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.3743 - val_loss: 0.3814\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.3720 - val_loss: 0.4673\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.3714 - val_loss: 0.3558\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.3682 - val_loss: 0.4288\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.3672 - val_loss: 0.3508\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.3648 - val_loss: 0.3617\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.3632 - val_loss: 0.3501\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.3616 - val_loss: 0.4700\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.3615 - val_loss: 0.3538\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 598us/step - loss: 0.3589 - val_loss: 0.4337\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.3582 - val_loss: 0.3588\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.3565 - val_loss: 0.3571\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.3558 - val_loss: 0.3497\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.3540 - val_loss: 0.3427\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.3535 - val_loss: 0.3496\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.3521 - val_loss: 0.3436\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 612us/step - loss: 0.3511 - val_loss: 0.4193\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.3513 - val_loss: 0.3373\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.3492 - val_loss: 0.4363\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.3500 - val_loss: 0.3405\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.3476 - val_loss: 0.4010\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.3481 - val_loss: 0.3436\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.3459 - val_loss: 0.5003\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 589us/step - loss: 0.3479 - val_loss: 0.3419\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.3450 - val_loss: 0.3513\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.3440 - val_loss: 0.3320\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.3431 - val_loss: 0.3329\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.3425 - val_loss: 0.4614\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.3422 - val_loss: 0.3631\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.3417 - val_loss: 0.5731\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.3422 - val_loss: 0.3297\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.3396 - val_loss: 0.3558\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 618us/step - loss: 0.3398 - val_loss: 0.3548\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.3390 - val_loss: 0.3571\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.3376 - val_loss: 0.3764\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.3380 - val_loss: 0.3315\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.3372 - val_loss: 0.3487\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.3355 - val_loss: 0.4303\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.3363 - val_loss: 0.3733\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 598us/step - loss: 0.3350 - val_loss: 0.3332\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.3349 - val_loss: 0.3244\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.3338 - val_loss: 0.3349\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.3343 - val_loss: 0.3341\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 598us/step - loss: 0.3331 - val_loss: 0.3457\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 614us/step - loss: 0.3323 - val_loss: 0.3575\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.3315 - val_loss: 0.3609\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.3315 - val_loss: 0.3275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.3301 - val_loss: 0.4465\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 573us/step - loss: 0.3311 - val_loss: 0.3236\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.3300 - val_loss: 0.3394\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 599us/step - loss: 0.3293 - val_loss: 0.3220\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.3289 - val_loss: 0.3266\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.3286 - val_loss: 0.3221\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.3278 - val_loss: 0.3351\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.3275 - val_loss: 0.3540\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 598us/step - loss: 0.3266 - val_loss: 0.3968\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.3259 - val_loss: 0.3394\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 577us/step - loss: 0.3254 - val_loss: 0.3775\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 602us/step - loss: 0.3251 - val_loss: 0.4113\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 581us/step - loss: 0.3259 - val_loss: 0.3193\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.3244 - val_loss: 0.4039\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 606us/step - loss: 0.3253 - val_loss: 0.3193\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.3242 - val_loss: 0.3175\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.3232 - val_loss: 0.3626\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.3236 - val_loss: 0.3306\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 585us/step - loss: 0.3223 - val_loss: 0.3182\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.3221 - val_loss: 0.3324\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 610us/step - loss: 0.3216 - val_loss: 0.3233\n",
      "121/121 [==============================] - 0s 342us/step - loss: 0.3303\n",
      "[CV] END learning_rate=0.0011587711178708176, n_hidden=3, n_neurons=40; total time=  15.2s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anpdi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 979us/step - loss: 1.1003 - val_loss: 11.4733\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.6576 - val_loss: 5.1121\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 685us/step - loss: 0.5167 - val_loss: 0.4830\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 685us/step - loss: 0.4187 - val_loss: 0.4206\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.3907 - val_loss: 0.4579\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 681us/step - loss: 0.3758 - val_loss: 0.3589\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 681us/step - loss: 0.3663 - val_loss: 0.4563\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.3594 - val_loss: 0.4158\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.3530 - val_loss: 0.3940\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 685us/step - loss: 0.3478 - val_loss: 0.3369\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.3434 - val_loss: 0.3530\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.3393 - val_loss: 0.3487\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 685us/step - loss: 0.3368 - val_loss: 0.3581\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.3326 - val_loss: 0.3852\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 685us/step - loss: 0.3308 - val_loss: 0.3417\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 689us/step - loss: 0.3280 - val_loss: 0.3959\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 681us/step - loss: 0.3261 - val_loss: 0.3245\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 681us/step - loss: 0.3223 - val_loss: 0.4177\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 685us/step - loss: 0.3223 - val_loss: 0.3217\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.3186 - val_loss: 0.3952\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.3178 - val_loss: 0.3483\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.3145 - val_loss: 0.3927\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 681us/step - loss: 0.3136 - val_loss: 0.3103\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.3123 - val_loss: 0.3334\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.3103 - val_loss: 0.3240\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 681us/step - loss: 0.3068 - val_loss: 0.3348\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 674us/step - loss: 0.3065 - val_loss: 0.3117\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 685us/step - loss: 0.3045 - val_loss: 0.3279\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 681us/step - loss: 0.3021 - val_loss: 0.4434\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.3020 - val_loss: 0.3096\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.3020 - val_loss: 0.3132\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.2983 - val_loss: 0.3209\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.2962 - val_loss: 0.3082\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 714us/step - loss: 0.2965 - val_loss: 0.3756\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 693us/step - loss: 0.2939 - val_loss: 0.3190\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 776us/step - loss: 0.2925 - val_loss: 0.2972\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 722us/step - loss: 0.2907 - val_loss: 0.4108\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 851us/step - loss: 0.2911 - val_loss: 0.2958\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 755us/step - loss: 0.2888 - val_loss: 0.3388\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 764us/step - loss: 0.2874 - val_loss: 0.3150\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.2871 - val_loss: 0.2984\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 693us/step - loss: 0.2855 - val_loss: 0.3243\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 648us/step - loss: 0.2850 - val_loss: 0.2939\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 652us/step - loss: 0.2842 - val_loss: 0.3843\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.2847 - val_loss: 0.2915\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 718us/step - loss: 0.2823 - val_loss: 0.3988\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 689us/step - loss: 0.2816 - val_loss: 0.3098\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 656us/step - loss: 0.2810 - val_loss: 0.3635\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 660us/step - loss: 0.2792 - val_loss: 0.2829\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 710us/step - loss: 0.2787 - val_loss: 0.3841\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 660us/step - loss: 0.2781 - val_loss: 0.2927\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 721us/step - loss: 0.2770 - val_loss: 0.3431\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 706us/step - loss: 0.2778 - val_loss: 0.2817\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 722us/step - loss: 0.2733 - val_loss: 0.3538\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.2743 - val_loss: 0.2968\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.2719 - val_loss: 0.4027\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.2728 - val_loss: 0.3744\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 708us/step - loss: 0.2733 - val_loss: 0.3831\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 768us/step - loss: 0.2713 - val_loss: 0.3096\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.2696 - val_loss: 0.5007\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 730us/step - loss: 0.2709 - val_loss: 0.2984\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 697us/step - loss: 0.2699 - val_loss: 0.4290\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 697us/step - loss: 0.2680 - val_loss: 0.2871\n",
      "121/121 [==============================] - 0s 383us/step - loss: 0.3238\n",
      "[CV] END learning_rate=0.004633158448989678, n_hidden=3, n_neurons=98; total time=  10.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anpdi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 963us/step - loss: 1.0446 - val_loss: 2.6113\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.5373 - val_loss: 0.6699\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.4499 - val_loss: 0.3994\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.4040 - val_loss: 0.3714\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 685us/step - loss: 0.3868 - val_loss: 0.4203\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 720us/step - loss: 0.3735 - val_loss: 0.5714\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 714us/step - loss: 0.3636 - val_loss: 0.5616\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 730us/step - loss: 0.3586 - val_loss: 0.6972\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 697us/step - loss: 0.3547 - val_loss: 0.7454\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 675us/step - loss: 0.3505 - val_loss: 0.8409\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.3465 - val_loss: 0.8731\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 714us/step - loss: 0.3436 - val_loss: 0.9039\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 697us/step - loss: 0.3399 - val_loss: 0.6574\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 697us/step - loss: 0.3363 - val_loss: 0.8164\n",
      "121/121 [==============================] - 0s 367us/step - loss: 0.3603\n",
      "[CV] END learning_rate=0.004633158448989678, n_hidden=3, n_neurons=98; total time=   2.9s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anpdi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 992us/step - loss: 0.9770 - val_loss: 2.2370\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.4834 - val_loss: 1.1238\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 660us/step - loss: 0.4207 - val_loss: 0.3692\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.3927 - val_loss: 0.4080\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 693us/step - loss: 0.3799 - val_loss: 0.4280\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 689us/step - loss: 0.3705 - val_loss: 0.3458\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 681us/step - loss: 0.3690 - val_loss: 0.3715\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 685us/step - loss: 0.3598 - val_loss: 0.3567\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 664us/step - loss: 0.3521 - val_loss: 0.4355\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 677us/step - loss: 0.3490 - val_loss: 0.3290\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.3433 - val_loss: 0.3737\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 676us/step - loss: 0.3408 - val_loss: 0.3441\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 681us/step - loss: 0.3377 - val_loss: 0.5061\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 718us/step - loss: 0.3367 - val_loss: 0.3213\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.3323 - val_loss: 0.4254\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.3300 - val_loss: 0.3897\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 781us/step - loss: 0.3271 - val_loss: 0.3376\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.3264 - val_loss: 0.3109\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.3218 - val_loss: 0.3706\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 689us/step - loss: 0.3226 - val_loss: 0.4157\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.3221 - val_loss: 0.3486\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 672us/step - loss: 0.3189 - val_loss: 0.3330\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.3164 - val_loss: 0.3172\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 668us/step - loss: 0.3148 - val_loss: 0.3543\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 656us/step - loss: 0.3134 - val_loss: 0.3142\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 685us/step - loss: 0.3096 - val_loss: 0.3078\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 735us/step - loss: 0.3103 - val_loss: 0.3136\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 710us/step - loss: 0.3085 - val_loss: 0.3276\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 722us/step - loss: 0.3047 - val_loss: 0.3013\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 730us/step - loss: 0.3041 - val_loss: 0.4252\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 714us/step - loss: 0.3050 - val_loss: 0.3039\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 718us/step - loss: 0.3019 - val_loss: 0.3705\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 701us/step - loss: 0.3023 - val_loss: 0.2935\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 739us/step - loss: 0.2984 - val_loss: 0.3846\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 739us/step - loss: 0.2987 - val_loss: 0.3001\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 760us/step - loss: 0.2960 - val_loss: 0.3408\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 780us/step - loss: 0.2958 - val_loss: 0.2918\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 751us/step - loss: 0.2944 - val_loss: 0.3814\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 743us/step - loss: 0.2930 - val_loss: 0.3004\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 793us/step - loss: 0.2920 - val_loss: 0.4726\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 747us/step - loss: 0.2936 - val_loss: 0.6583\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 685us/step - loss: 0.2948 - val_loss: 0.7079\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 685us/step - loss: 0.2955 - val_loss: 0.3514\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 722us/step - loss: 0.2902 - val_loss: 0.5274\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 718us/step - loss: 0.2906 - val_loss: 0.3253\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 697us/step - loss: 0.2866 - val_loss: 0.3216\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 760us/step - loss: 0.2851 - val_loss: 0.3265\n",
      "121/121 [==============================] - 0s 383us/step - loss: 0.3013\n",
      "[CV] END learning_rate=0.004633158448989678, n_hidden=3, n_neurons=98; total time=   8.4s\n",
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 873us/step - loss: 0.8698 - val_loss: 2.3043\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 619us/step - loss: 0.4709 - val_loss: 1.8981\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 619us/step - loss: 0.4125 - val_loss: 0.5889\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 619us/step - loss: 0.3804 - val_loss: 0.4142\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 616us/step - loss: 0.3639 - val_loss: 0.3813\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 611us/step - loss: 0.3568 - val_loss: 0.4249\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 608us/step - loss: 0.3517 - val_loss: 0.3285\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 611us/step - loss: 0.3443 - val_loss: 0.4200\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 608us/step - loss: 0.3417 - val_loss: 0.4674\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 613us/step - loss: 0.3376 - val_loss: 0.3352\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 613us/step - loss: 0.3334 - val_loss: 0.3266\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 611us/step - loss: 0.3283 - val_loss: 0.3551\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 605us/step - loss: 0.3264 - val_loss: 0.3795\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 616us/step - loss: 0.3221 - val_loss: 0.3674\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 608us/step - loss: 0.3194 - val_loss: 0.4675\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 613us/step - loss: 0.3206 - val_loss: 0.3524\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 611us/step - loss: 0.3139 - val_loss: 0.3742\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 611us/step - loss: 0.3119 - val_loss: 0.3645\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 611us/step - loss: 0.3105 - val_loss: 0.3212\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 611us/step - loss: 0.3083 - val_loss: 0.3266\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 624us/step - loss: 0.3057 - val_loss: 0.3883\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 609us/step - loss: 0.3057 - val_loss: 0.3004\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 611us/step - loss: 0.3031 - val_loss: 0.2947\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 606us/step - loss: 0.3011 - val_loss: 0.4210\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 613us/step - loss: 0.3021 - val_loss: 0.5314\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 611us/step - loss: 0.3008 - val_loss: 0.7953\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 608us/step - loss: 0.3002 - val_loss: 0.3583\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 608us/step - loss: 0.2947 - val_loss: 0.4285\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 616us/step - loss: 0.2931 - val_loss: 0.2847\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 616us/step - loss: 0.2912 - val_loss: 0.2952\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 0s 611us/step - loss: 0.2890 - val_loss: 0.2999\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 602us/step - loss: 0.2894 - val_loss: 0.3783\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 626us/step - loss: 0.2880 - val_loss: 0.4138\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 649us/step - loss: 0.2882 - val_loss: 0.3200\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 644us/step - loss: 0.2850 - val_loss: 0.3692\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 600us/step - loss: 0.2832 - val_loss: 0.3018\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 594us/step - loss: 0.2821 - val_loss: 0.2937\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 600us/step - loss: 0.2805 - val_loss: 0.2854\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 605us/step - loss: 0.2791 - val_loss: 0.3158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x00000214B5D6FB80>,\n",
       "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000214B5CC9EB0>,\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n",
       "       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n",
       "       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "762a8a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.004633158448989678, 'n_hidden': 3, 'n_neurons': 98}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "282fe302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.32845015327135724"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bb0e0583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor at 0x214bec470a0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a60f7604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 360us/step - loss: 0.2998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.2998284697532654"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a057b89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 379us/step - loss: 0.2998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2998284697532654"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = rnd_search_cv.best_estimator_.model\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9353463b",
   "metadata": {},
   "source": [
    "## 연습문제 10\n",
    "Deep MLP를 MNIST 데이터셋에 훈련해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "94b69462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ddd13ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0c439827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b580b486",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "258f15da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0], cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "45ffc483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 3, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e6552f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x345.6 with 40 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_rows = 4\n",
    "n_cols = 10\n",
    "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\n",
    "        plt.axis('off')\n",
    "        plt.title(y_train[index], fontsize=12)\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f741c61",
   "metadata": {},
   "source": [
    "간단한 밀집 신경망을 만들고 최적의 학습률을 찾아 보겠습니다. 반복마다 학습률을 증가시키기 위해 콜백을 사용합니다. 이 콜백은 반복마다 학습률과 손실을 기록합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "21ef39df",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "\n",
    "class ExponentialLearningRate(keras.callbacks.Callback):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        self.rates = []\n",
    "        self.losses = []\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.rates.append(K.get_value(self.model.optimizer.lr))\n",
    "        self.losses.append(logs[\"loss\"])\n",
    "        K.set_value(self.model.optimizer.lr, self.model.optimizer.lr * self.factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8e2d8751",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e4337458",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6165110b",
   "metadata": {},
   "source": [
    "작은 학습률 1e-3에서 시작하여 반복마다 0.5%씩 증가합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6e646a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=1e-3),\n",
    "              metrics=[\"accuracy\"])\n",
    "expon_lr = ExponentialLearningRate(factor=1.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5104d1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 2s 1ms/step - loss: 1.4194 - accuracy: 0.5898 - val_loss: 2.3911 - val_accuracy: 0.1126\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[expon_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fac43e9",
   "metadata": {},
   "source": [
    "학습률에 대한 로스 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "13a1d5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(expon_lr.rates, expon_lr.losses)\n",
    "plt.gca().set_xscale('log')\n",
    "plt.hlines(min(expon_lr.losses), min(expon_lr.rates), max(expon_lr.rates))\n",
    "plt.axis([min(expon_lr.rates), max(expon_lr.rates), 0, expon_lr.losses[0]])\n",
    "plt.grid()\n",
    "plt.xlabel(\"Learning rate\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98d14ea",
   "metadata": {},
   "source": [
    "학습률이 6e-1을 지날 떄 손실이 갑자기 솟구치기 때문에 3e-1을 학습률로 사용하겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e77fff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6d6c7076",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=3e-1),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3113fe02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_mnist_logs\\\\run_001'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_index = 1 # 실행할 때마다 이 값을 늘립니다\n",
    "run_logdir = os.path.join(os.curdir, \"my_mnist_logs\", \"run_{:03d}\".format(run_index))\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ca43ba4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2342 - accuracy: 0.9270 - val_loss: 0.1110 - val_accuracy: 0.9682\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.0939 - accuracy: 0.9711 - val_loss: 0.0827 - val_accuracy: 0.9756\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.0644 - accuracy: 0.9795 - val_loss: 0.0700 - val_accuracy: 0.9796\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.0462 - accuracy: 0.9852 - val_loss: 0.0841 - val_accuracy: 0.9784\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.0370 - accuracy: 0.9879 - val_loss: 0.0975 - val_accuracy: 0.9738\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.0266 - accuracy: 0.9914 - val_loss: 0.0746 - val_accuracy: 0.9814\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.0236 - accuracy: 0.9921 - val_loss: 0.0864 - val_accuracy: 0.9814\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.0180 - accuracy: 0.9946 - val_loss: 0.0871 - val_accuracy: 0.9784\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.0137 - accuracy: 0.9953 - val_loss: 0.0825 - val_accuracy: 0.9824\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.0130 - accuracy: 0.9956 - val_loss: 0.1044 - val_accuracy: 0.9802\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 0.0952 - val_accuracy: 0.9812\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 0.0865 - val_accuracy: 0.9820\n",
      "Epoch 13/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.0856 - val_accuracy: 0.9838\n",
      "Epoch 14/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 0.1045 - val_accuracy: 0.9826\n",
      "Epoch 15/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.0845 - val_accuracy: 0.9834\n",
      "Epoch 16/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.0916 - val_accuracy: 0.9840\n",
      "Epoch 17/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0831 - val_accuracy: 0.9848\n",
      "Epoch 18/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 3.7818e-04 - accuracy: 1.0000 - val_loss: 0.0805 - val_accuracy: 0.9860\n",
      "Epoch 19/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 1.0586e-04 - accuracy: 1.0000 - val_loss: 0.0814 - val_accuracy: 0.9860\n",
      "Epoch 20/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 7.2452e-05 - accuracy: 1.0000 - val_loss: 0.0827 - val_accuracy: 0.9860\n",
      "Epoch 21/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 6.0177e-05 - accuracy: 1.0000 - val_loss: 0.0834 - val_accuracy: 0.9866\n",
      "Epoch 22/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 5.2077e-05 - accuracy: 1.0000 - val_loss: 0.0842 - val_accuracy: 0.9864\n",
      "Epoch 23/100\n",
      "1719/1719 [==============================] - 2s 1ms/step - loss: 4.6327e-05 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9864\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=20)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_mnist_model.h5\", save_best_only=True)\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b3edcbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 583us/step - loss: 0.0771 - accuracy: 0.9771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07708481699228287, 0.9771000146865845]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_mnist_model.h5\") # rollback to best model\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e3a7bf4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b9ac2ecb98aafdb0\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b9ac2ecb98aafdb0\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=./my_mnist_logs --port=6006"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
